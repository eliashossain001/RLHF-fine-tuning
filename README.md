# LLM Fine-Tune & Preference Optimization

This repository contains two key components for training and optimizing Large Language Models (LLMs):

- âœ… **Supervised Fine-Tuning (SFT)** using GPT-4-style models for math problem-solving
- âœ… **Direct Preference Optimization (DPO)** to further align LLM behavior with preference data, using models such as Qwen



---

## ğŸš€ Fine-Tuning GPT-4 for Math Problem Solving

This section focuses on fine-tuning a GPT-style model on a **math reasoning task** using a large dataset of structured QA pairs.

### ğŸ“š Dataset Details

We used a publicly available dataset containing **395,000 math questions** with step-by-step solutions. Each entry includes:

- `original_question`: the input math problem  
- `response`: a detailed, multi-step solution

The questions span a wide range of topics â€” from basic arithmetic to advanced algebra and functional equations â€” making it a strong benchmark for testing **LLM mathematical reasoning**.

### ğŸ›  Technologies
- ğŸ¤– Model: GPT-4-style (any causal LM)
- ğŸ“– Framework: [Unsloth](https://github.com/unslothai/unsloth) for fast fine-tuning
- ğŸ’¾ Tokenizer: AutoTokenizer from Hugging Face
- ğŸ“Š Evaluation: Sample generations and accuracy on held-out test sets

---

## ğŸ¯ Direct Preference Optimization (DPO)

The DPO section focuses on **optimizing LLM outputs** beyond standard SFT by learning from **preference pairs**. This allows models to choose preferred completions aligned with user expectations.

### ğŸ§ª Current Setup

- ğŸ” Model: [`Qwen/Qwen2.5-0.5B-Instruct`](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)
- âš™ï¸ Optimizer: DPOTrainer (from `trl` or equivalent)
- ğŸ” Preference Data: Synthetic titles and step-by-step completions
- ğŸ“ Notebooks include:
  - Data generation
  - Dataset formatting
  - Fine-tuning with DPO
  - Evaluation and visualization

### ğŸ’¡ Future Work

We aim to:
- Experiment with larger models (e.g., `Qwen-1.8B`, `LLaMA-3`, `Mixtral`)
- Compare SFT-only vs SFT+DPO pipelines
- Explore human preference data injection

---

## ğŸ§° Requirements

```bash
pip install -r requirements.txt


